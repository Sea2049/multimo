# Multimo 项目全面测试与回溯计划

## 📋 项目现状分析

### 当前架构
- **前端**: Vue.js 3 + Vite + D3.js (图谱可视化)
- **后端**: Flask 3.0 + Python 3.11-3.12
- **核心依赖**: 
  - OASIS 0.2.5 (社交模拟引擎)
  - Zep Cloud 3.13.0 (长期记忆)
  - OpenAI SDK (LLM 交互)
- **测试框架**: 
  - 后端: pytest + pytest-cov
  - 前端: Vitest + @vue/test-utils

### 已有测试覆盖
- ✅ 图谱构建模块测试 (78个测试用例)
- ✅ 报告生成模块测试
- ✅ 模拟运行器测试
- ✅ CI/CD 配置 (GitHub Actions)

## 🎯 测试与回溯计划

### 阶段 1: 环境验证与依赖检查 (10分钟)

**目标**: 确保开发环境完整可用

1. **检查环境配置**
   - 验证 `.env` 文件配置完整性
   - 检查 Python 依赖 (backend/requirements.txt)
   - 检查 Node.js 依赖 (frontend/package.json)
   - 验证 API 密钥配置 (LLM_API_KEY, ZEP_API_KEY)

2. **依赖安全扫描**
   - 检查 Python 依赖漏洞
   - 检查 Node.js 依赖漏洞
   - 验证依赖版本兼容性

3. **服务健康检查**
   - 启动后端服务 (Flask)
   - 启动前端服务 (Vite)
   - 测试健康检查端点 (GET /api/v1/health)

### 阶段 2: 后端单元测试 (15分钟)

**目标**: 验证核心模块功能正确性

1. **运行完整测试套件**
   ```bash
   cd backend
   pytest --cov=app tests/ -v
   ```

2. **测试覆盖模块**
   - 图谱构建模块 (extractor, builder, storage)
   - 报告生成模块 (analyzer, generator)
   - 模拟运行器 (simulation_runner)

3. **生成覆盖率报告**
   - 代码覆盖率统计
   - 未覆盖代码识别
   - 覆盖率目标: > 70%

### 阶段 3: 前端测试 (10分钟)

**目标**: 验证前端组件和交互

1. **运行前端测试**
   ```bash
   cd frontend
   npm test -- --run
   ```

2. **组件测试**
   - 核心组件渲染测试
   - API 客户端测试
   - 路由测试

### 阶段 4: API 集成测试 (20分钟)

**目标**: 验证 API 端点功能和错误处理

1. **图谱构建 API**
   - POST /api/v1/graph/ontology/generate (本体生成)
   - POST /api/v1/graph/extract (实体提取)
   - POST /api/v1/graph/build (图谱构建)
   - GET /api/v1/graph/{graph_id} (获取图谱)
   - GET /api/v1/graph/{graph_id}/export (导出图谱)

2. **模拟控制 API**
   - POST /api/v1/simulation/create (创建模拟)
   - POST /api/v1/simulation/prepare (准备环境)
   - POST /api/v1/simulation/start (启动模拟)
   - GET /api/v1/simulation/status (查询状态)
   - POST /api/v1/simulation/stop (停止模拟)

3. **自动驾驶模式 API**
   - POST /api/v1/simulation/auto-pilot/config (配置模式)
   - POST /api/v1/simulation/auto-pilot/start (启动自动驾驶)
   - GET /api/v1/simulation/auto-pilot/status (查询状态)
   - POST /api/v1/simulation/auto-pilot/pause (暂停)
   - POST /api/v1/simulation/auto-pilot/resume (恢复)

4. **报告生成 API**
   - POST /api/v1/report/generate (生成报告)
   - GET /api/v1/report/{simulation_id} (获取报告)
   - GET /api/v1/report/{simulation_id}/markdown (Markdown格式)

5. **交互对话 API**
   - POST /api/v1/interaction/chat (与 ReportAgent 对话)

### 阶段 5: 端到端功能测试 (25分钟)

**目标**: 验证完整工作流程

1. **流程 1: 图谱构建流程**
   - 上传测试文档 (PDF/MD/TXT)
   - 提取实体和关系
   - 构建知识图谱
   - 验证图谱数据结构
   - 导出图谱数据

2. **流程 2: 环境准备流程**
   - 读取实体数据
   - 生成智能体人设 (Profile)
   - 生成模拟配置文件
   - 验证配置完整性

3. **流程 3: 模拟运行流程** (轻量级测试)
   - 创建模拟任务
   - 准备模拟环境
   - 启动短时模拟 (2-3轮)
   - 监控运行状态
   - 验证日志输出
   - 停止模拟

4. **流程 4: 报告生成流程**
   - 基于模拟数据生成报告
   - 验证报告结构
   - 检查报告内容质量
   - 导出 Markdown 格式

5. **流程 5: 自动驾驶模式测试**
   - 配置自动驾驶模式
   - 启动自动驾驶
   - 验证自动准备
   - 验证自动启动
   - 测试暂停/恢复功能

### 阶段 6: 安全性检查 (15分钟)

**目标**: 识别安全风险和漏洞

1. **代码安全审查**
   - 检查敏感信息泄露 (API Key, 密码)
   - 验证 .env 文件不在版本控制中
   - 检查日志中的敏感信息

2. **输入验证测试**
   - SQL 注入测试 (如适用)
   - XSS 攻击测试
   - 文件上传安全测试
   - 路径遍历测试

3. **API 安全测试**
   - 认证机制测试 (如已启用)
   - 请求限流测试
   - CORS 配置验证
   - 安全响应头检查

4. **依赖漏洞扫描**
   - Python 依赖安全检查
   - Node.js 依赖安全检查

### 阶段 7: 性能测试 (15分钟)

**目标**: 评估系统性能指标

1. **API 响应时间测试**
   - 图谱构建 API 响应时间
   - 模拟控制 API 响应时间
   - 报告生成 API 响应时间
   - 目标: < 2秒 (非 LLM 调用)

2. **并发测试**
   - 多用户并发请求测试
   - 并发模拟数测试
   - 目标: 支持 10+ 并发模拟

3. **资源使用监控**
   - 内存使用情况
   - CPU 使用情况
   - 磁盘 I/O 性能

4. **文件处理性能**
   - 大文件上传测试 (接近 50MB)
   - PDF 解析性能
   - 图谱导出性能

### 阶段 8: 代码质量回溯 (20分钟)

**目标**: 评估代码质量和可维护性

1. **代码结构审查**
   - 模块化设计评估
   - 分层架构一致性
   - 代码复用情况
   - 命名规范检查

2. **文档完整性检查**
   - README 准确性验证
   - API 文档与实际一致性
   - FRAMEWORK.md 更新状态
   - CODE_DIRECTORY.md 完整性
   - 代码注释覆盖率

3. **错误处理审查**
   - 异常捕获完整性
   - 错误日志记录
   - 用户友好的错误消息
   - 错误恢复机制

4. **配置管理审查**
   - 环境变量使用规范
   - 配置文件结构
   - 默认值设置合理性

### 阶段 9: 兼容性测试 (10分钟)

**目标**: 验证跨平台兼容性

1. **Python 版本兼容性**
   - Python 3.11 测试
   - Python 3.12 测试

2. **Node.js 版本兼容性**
   - Node.js 18+ 测试

3. **浏览器兼容性**
   - Chrome 测试
   - Firefox 测试
   - Edge 测试

4. **操作系统兼容性**
   - Windows 环境测试
   - Linux 环境测试 (如可用)
   - macOS 环境测试 (如可用)

### 阶段 10: 回溯分析与报告 (15分钟)

**目标**: 总结测试结果并提供改进建议

1. **测试结果汇总**
   - 通过的测试数量
   - 失败的测试详情
   - 代码覆盖率统计
   - 性能指标汇总

2. **问题清单**
   - 严重问题 (P0)
   - 重要问题 (P1)
   - 一般问题 (P2)
   - 优化建议

3. **改进建议**
   - 代码质量改进
   - 性能优化建议
   - 安全加固建议
   - 测试覆盖增强

4. **生成测试报告**
   - 测试执行摘要
   - 详细测试结果
   - 问题追踪清单
   - 后续行动计划

## 📊 成功标准

- ✅ 单元测试通过率 > 95%
- ✅ 代码覆盖率 > 70%
- ✅ 核心 API 端点正常响应
- ✅ 无严重安全漏洞 (P0)
- ✅ 文档与代码一致
- ✅ 性能指标达标

## ⚠️ 注意事项

1. **API 配额**: 完整模拟测试会消耗 LLM API 配额,建议使用短时模拟
2. **测试数据**: 使用测试数据,不影响生产环境
3. **环境隔离**: 测试在独立环境中进行
4. **备份**: 测试前备份重要数据

## 📝 测试输出

测试完成后将生成:
1. **测试执行报告** - 详细的测试结果和统计
2. **代码覆盖率报告** - HTML 格式的覆盖率报告
3. **问题追踪清单** - 发现的问题和优先级
4. **性能基准报告** - 关键性能指标
5. **安全评估报告** - 安全检查结果
6. **改进建议文档** - 后续优化方向

## ⏱️ 预计总时间: 约 155 分钟 (2.5 小时)

## 🚀 执行方式

测试将按阶段顺序执行,每个阶段完成后会生成阶段报告。如果发现严重问题 (P0),会立即报告并建议是否继续后续测试。

是否开始执行此测试与回溯计划?